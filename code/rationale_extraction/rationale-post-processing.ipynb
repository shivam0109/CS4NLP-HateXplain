{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12fab03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Post-Processing of Generated output from Hugchat \n",
    "1. Extract label, community, rationale and keywords \n",
    "2. Create dataset which removes all \"-1\" tags \n",
    "3. Convert labels into: hate, offensive, normal speech. \n",
    "4. Convert communities targeted from the list ['African', 'Islam', 'Jewish', 'Homosexual', 'Women', 'Refugee', 'Arab', 'Caucasian', 'Asian', 'Hispanic']\n",
    "5. Check if keywords are present in the sentence. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55189f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import difflib\n",
    "import string\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a010023",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### INPUT \n",
    "df_rationale_path = '../../data/rationale_extraction/df_train_with_rationales.csv'\n",
    "\n",
    "### Output \n",
    "df_rationale_post_processed_path = '../../data/rationale_extraction/df_rationale_post_processed.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ec904b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14616, 8)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(df_rationale_path)\n",
    "df.dropna(subset=['hugchat_response'], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "652c5d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract classification label from hugchat responses\n",
    "# Split the text response by '\\n'. Split sentences by ':'. Check for current phrase in the list to be similar to 'classification'. \n",
    "# Return the next phrase\n",
    "\n",
    "def extract_label(hugchat_response):\n",
    "    text = hugchat_response.lower()\n",
    "    text_list = text.split('\\n')\n",
    "    for sentence in text_list:\n",
    "        phrases = sentence.split(\":\")\n",
    "        for i in range(len(phrases)):\n",
    "            if phrases[i].strip() in ['classification']:\n",
    "                if i+1<len(phrases):\n",
    "                    return phrases[i+1]\n",
    "            elif phrases[i].strip() in ['output part1', 'output part 1', 'output 1', 'output part i', 'part1', 'first part']:\n",
    "                # check next word is not 'classification'\n",
    "                if i+1<len(phrases):\n",
    "                    s = difflib.SequenceMatcher(None, \"classification\", phrases[i+1].strip())\n",
    "                    if s.ratio() >= 0.80 and (i+2)<len(phrases):\n",
    "                        return phrases[i+2]\n",
    "                    else:\n",
    "                        return phrases[i+1]\n",
    "            else:\n",
    "                s = difflib.SequenceMatcher(None, \"classification\", phrases[i].strip())\n",
    "                if (s.ratio()>=0.70) and (i+1)<len(phrases):\n",
    "                    return phrases[i+1]\n",
    "                else:\n",
    "                    s = difflib.SequenceMatcher(None, \"output start\", phrases[i].strip())\n",
    "                    t = difflib.SequenceMatcher(None, \"start\", phrases[i].strip())\n",
    "                    if (s.ratio()>0.9) and (i+1)<len(phrases):\n",
    "                        if phrases[i+1].strip() in ['normal', 'normal speech', 'hateful', 'hateful speech', 'hate speech', 'offensive', 'offensive speech']:\n",
    "                            return phrases[i+1]\n",
    "                    if (t.ratio()>0.9) and (i+1)<len(phrases):\n",
    "                        if phrases[i+1].strip() in ['normal', 'normal speech', 'hateful', 'hateful speech', 'hate speech', 'offensive', 'offensive speech']:\n",
    "                            return phrases[i+1]\n",
    "            \n",
    "    return \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47c686ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract targeted communities from hugchat responses\n",
    "# Split the text response by '\\n'. Split sentences by ':'. Check for current phrase in the list to be similar to 'communities targeted'. \n",
    "# Return the next phrase\n",
    "\n",
    "def extract_comm_targeted(hugchat_response):\n",
    "    text = hugchat_response.lower()\n",
    "    text_list = text.split('\\n')\n",
    "    for sentence in text_list:\n",
    "        phrases = sentence.split(\":\")\n",
    "        for i in range(len(phrases)):\n",
    "            if phrases[i].strip() in ['communities targeted', 'community targeted', 'targeted community', 'targeted communities', 'targeted Community(ies)']:\n",
    "                if i+1<len(phrases):\n",
    "                    return phrases[i+1]\n",
    "            elif phrases[i].strip() in ['output part2', 'output part 2', 'output 2', 'output part ii', 'part2', 'second part']:\n",
    "                # check next word is not communities targeted\n",
    "                if i+1<len(phrases):\n",
    "                    s = difflib.SequenceMatcher(None, \"communities targeted\", phrases[i+1].strip())\n",
    "                    if s.ratio() >= 0.60 and (i+2)<len(phrases):\n",
    "                        return phrases[i+2]\n",
    "                    else:\n",
    "                        return phrases[i+1]\n",
    "            else:\n",
    "                s = difflib.SequenceMatcher(None, \"communities targeted\", phrases[i].strip())\n",
    "                t = difflib.SequenceMatcher(None, \"targeted communities\", phrases[i].strip())\n",
    "                u = difflib.SequenceMatcher(None, \"community targeted\", phrases[i].strip())\n",
    "                v = difflib.SequenceMatcher(None, \"targeted community\", phrases[i].strip())\n",
    "                if (max(s.ratio(),t.ratio(), u.ratio(), v.ratio())>=0.60) and (i+1)<len(phrases):\n",
    "                    return phrases[i+1]\n",
    "    return \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5ae6cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract targeted communities from hugchat responses\n",
    "# Split the text response by '\\n'. Split sentences by ':'. Check for current phrase in the list to be similar to 'explanation'. \n",
    "# Return the next phrase\n",
    "\n",
    "def extract_rationale(hugchat_response):\n",
    "    text = hugchat_response.lower()\n",
    "    text_list = text.split('\\n')\n",
    "    #print(\"Text list: \\n\", text_list)\n",
    "    for sentence in text_list:\n",
    "        #print(\"Sentence: \", sentence)\n",
    "        phrases = sentence.split(\":\")\n",
    "        for i in range(len(phrases)):\n",
    "            #print(\"current phrase: \", phrases[i])\n",
    "            if phrases[i].strip() in ['explanation', 'justification', '* explanation', '### explanation ###', 'explancement', 'explaining my answer']:\n",
    "                if i+1<len(phrases):\n",
    "                    return phrases[i+1]\n",
    "            elif phrases[i].strip() in ['output part3', 'output part 3', 'output 3', 'output part iii', 'part3', 'third part']:\n",
    "                # check next word is not explanation\n",
    "                if i+1<len(phrases):\n",
    "                    s = difflib.SequenceMatcher(None, \"explanation\", phrases[i+1].strip())\n",
    "                    if s.ratio() >= 0.80 and (i+2)<len(phrases):\n",
    "                        return phrases[i+2]\n",
    "                    else:\n",
    "                        return phrases[i+1]\n",
    "            elif 'explanation' in phrases[i].strip():\n",
    "                if (i+1)<len(phrases):\n",
    "                    if len(phrases[i+1].split()) > 20:\n",
    "                        return phrases[i+1]\n",
    "            else:\n",
    "                s = difflib.SequenceMatcher(None, \"explanation\", phrases[i].strip())\n",
    "                t = difflib.SequenceMatcher(None, \"justification\", phrases[i].strip())\n",
    "                if (max(s.ratio(),t.ratio())>=0.80) and (i+1)<len(phrases):\n",
    "                    return phrases[i+1]\n",
    "    return \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59b8a1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract keywords from hugchat responses\n",
    "# Split the text response by '\\n'. Split sentences by ':'. Check for current phrase in the list to be similar to 'keywords'. \n",
    "# Return the next phrase\n",
    "\n",
    "def extract_keywords(hugchat_response):\n",
    "    text = hugchat_response.lower()\n",
    "    text_list = text.split('\\n')\n",
    "    #print(\"Text list: \\n\", text_list)\n",
    "    for sentence in text_list:\n",
    "        #print(\"Sentence: \", sentence)\n",
    "        phrases = sentence.split(\":\")\n",
    "        for i in range(len(phrases)):\n",
    "            #print(\"current phrase: \", phrases[i])\n",
    "            if phrases[i].strip() in ['keywords', 'key word', 'keywords', 'key words']:\n",
    "                if i+1<len(phrases):\n",
    "                    return phrases[i+1]\n",
    "            elif phrases[i].strip() in ['output part4', 'output part 4', 'output 4', 'output part iv', 'part4', 'part 4', 'fourth part']:\n",
    "                # check next word is not 'keywords'\n",
    "                if i+1<len(phrases):\n",
    "                    s = difflib.SequenceMatcher(None, \"keywords\", phrases[i+1].strip())\n",
    "                    if s.ratio() >= 0.80 and (i+2)<len(phrases):\n",
    "                        return phrases[i+2]\n",
    "                    else:\n",
    "                        return phrases[i+1]\n",
    "            elif 'key' in phrases[i].strip():\n",
    "                if (i+1)<len(phrases):\n",
    "                    if len(phrases[i+1].split()) < 20:\n",
    "                        return phrases[i+1]\n",
    "            else:\n",
    "                s = difflib.SequenceMatcher(None, \"keyword\", phrases[i].strip())\n",
    "                if (s.ratio()>=0.80) and (i+1)<len(phrases):\n",
    "                    return phrases[i+1]\n",
    "    return \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a823b433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove all entries which have \"-1\" in any of the field \n",
    "def drop_no_output_rows(df):\n",
    "    print(\"Intital shape: \", df.shape)\n",
    "    df_copy = df.copy()\n",
    "    print(\"label -1 rows : \", df_copy[df_copy['hugchat_label']==\"-1\"].shape[0])\n",
    "    df_copy = df_copy[df_copy['hugchat_label']!=\"-1\"].copy()\n",
    "    print(\"comm targeted -1 : \", df_copy[df_copy['hugchat_comm_targeted']==\"-1\"].shape[0])\n",
    "    df_copy = df_copy[df_copy['hugchat_comm_targeted']!=\"-1\"].copy()\n",
    "    print(\"keywords -1 : \", df_copy[df_copy['hugchat_keywords']==\"-1\"].shape[0])\n",
    "    df_copy = df_copy[df_copy['hugchat_keywords']!=\"-1\"].copy()\n",
    "    print(\"explanation -1 : \", df_copy[df_copy['hugchat_explanation']==\"-1\"].shape[0])\n",
    "    df_copy = df_copy[df_copy['hugchat_explanation']!=\"-1\"].copy()\n",
    "    print(\"Final shape: \",df_copy.shape)\n",
    "    return df_copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "655b3f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert hugchat labels into \"hate\", \"offensive\", \"normal\". \n",
    "# Some responses have hate/offensive. Labels are overindexed on hate speech, prioritizing offensive over hate and normal.\n",
    "# Priority Order: hate < normal < offensive\n",
    "def convert_hugchat_label(hugchat_label):\n",
    "    label = ''\n",
    "    hugchat_label = hugchat_label.strip()\n",
    "    if \"hate\" in hugchat_label:\n",
    "        label = \"hate_speech\"\n",
    "    if \"normal\" in hugchat_label:\n",
    "        label = \"normal_speech\"\n",
    "    if \"offensive\" in hugchat_label:\n",
    "        label = \"offensive_speech\"\n",
    "    return label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5caea2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert hugchat comm targeted into ['African', 'Islam', 'Jewish', 'Homosexual', 'Women', 'Refugee', 'Arab', 'Caucasian', 'Asian', 'Hispanic', 'None'] \n",
    "def convert_comm_targeted(hugchat_comm_targeted):\n",
    "    hugchat_comm_targeted = hugchat_comm_targeted.strip()\n",
    "    hugchat_comm_targeted = hugchat_comm_targeted.translate(str.maketrans('', '', string.punctuation))\n",
    "    comm_target = []\n",
    "    none_list = ['none', 'na', 'not applicable', 'not specified']\n",
    "    islam_list = ['islam', 'muslim', 'moslem', 'muslims', 'moslems']\n",
    "    homosexual_list = ['homo','gay','lgbtq', 'lesbian','queer']\n",
    "    women_list = ['women', 'female', 'feminist']\n",
    "    refugee_list = ['refugee', 'migrant', 'immigrant']\n",
    "    african_list = ['african','black']\n",
    "    asian_list = ['asian', 'india', 'pakistan', 'bangla']\n",
    "    hispanic_list = ['latin','hispanic']\n",
    "    \n",
    "    for item in none_list:\n",
    "        if item in hugchat_comm_targeted:\n",
    "            comm_target.append('none')\n",
    "    \n",
    "    for item in african_list:\n",
    "        if item in hugchat_comm_targeted:\n",
    "            comm_target.append('african')\n",
    "    \n",
    "    for item in islam_list:\n",
    "        if item in hugchat_comm_targeted:\n",
    "            comm_target.append('islam')\n",
    "    \n",
    "    if 'jew' in hugchat_comm_targeted:\n",
    "        comm_target.append('jewish')\n",
    "    \n",
    "    if 'arab' in hugchat_comm_targeted:\n",
    "        comm_target.append('arab')\n",
    "    \n",
    "    if 'white' in hugchat_comm_targeted:\n",
    "        comm_target.append('caucasian')\n",
    "    \n",
    "    for item in asian_list:\n",
    "        if item in hugchat_comm_targeted:\n",
    "            comm_target.append('asian')\n",
    "    \n",
    "    for item in hispanic_list:\n",
    "        if item in hugchat_comm_targeted:\n",
    "            comm_target.append('hispanic')\n",
    "    \n",
    "    for item in women_list:\n",
    "        if item in hugchat_comm_targeted:\n",
    "            comm_target.append('women')\n",
    "    \n",
    "    for item in homosexual_list:\n",
    "        if item in hugchat_comm_targeted:\n",
    "            comm_target.append('homosexual')\n",
    "    \n",
    "    for item in refugee_list:\n",
    "        if item in hugchat_comm_targeted:\n",
    "            comm_target.append('refugee')\n",
    "    \n",
    "    if ('none' in comm_target) and (len(comm_target)>1):\n",
    "        comm_target = [x for x in comm_target if x!='none']\n",
    "    \n",
    "    return list(set(comm_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53bf500a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check to return hugchat keywords present in the sentence. \n",
    "\n",
    "def convert_hugchat_keywords(sentence, hugchat_keywords):\n",
    "    kw_list = []\n",
    "    sentence = sentence.translate(str.maketrans('', '', string.punctuation))\n",
    "    words = sentence.split()\n",
    "    words = [word for word in words if word not in stopwords.words('english')]\n",
    "    kwords = hugchat_keywords.split()\n",
    "    for kw in kwords:\n",
    "        kw = kw.strip()\n",
    "        for word in words:\n",
    "            word = word.strip()\n",
    "            s = difflib.SequenceMatcher(None, word, kw)\n",
    "            if s.ratio()>=0.7:\n",
    "                kw_list.append(word)\n",
    "    return list(set(kw_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a90385f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intital shape:  (14616, 12)\n",
      "label -1 rows :  164\n",
      "comm targeted -1 :  151\n",
      "keywords -1 :  140\n",
      "explanation -1 :  211\n",
      "Final shape:  (13950, 12)\n",
      "(13950, 15)\n"
     ]
    }
   ],
   "source": [
    "# Get outputs from Hugchat Response\n",
    "df['hugchat_label'] = df['hugchat_response'].apply(lambda x: extract_label(x))\n",
    "df['hugchat_comm_targeted'] = df['hugchat_response'].apply(lambda x: extract_comm_targeted(x))\n",
    "df['hugchat_explanation'] = df['hugchat_response'].apply(lambda x: extract_rationale(x))\n",
    "df['hugchat_keywords'] = df['hugchat_response'].apply(lambda x: extract_keywords(x))\n",
    "\n",
    "# Process these outputs\n",
    "df_filtered = drop_no_output_rows(df)\n",
    "df_filtered['hugchat_label_processed'] = df_filtered['hugchat_label'].apply(lambda x: convert_hugchat_label(x))\n",
    "df_filtered['hugchat_comm_targeted_processed'] = df_filtered['hugchat_comm_targeted'].apply(lambda x: convert_comm_targeted(x))\n",
    "df_filtered['hugchat_keywords_processed'] = df_filtered[['unmasked_sentence','hugchat_keywords']].apply(lambda row: convert_hugchat_keywords(row['unmasked_sentence'], row['hugchat_keywords']), axis=1)\n",
    "\n",
    "\n",
    "print(df_filtered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7481d5ef",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>annotators</th>\n",
       "      <th>rationales</th>\n",
       "      <th>post_tokens</th>\n",
       "      <th>masked_tokens</th>\n",
       "      <th>unmasked_sentence</th>\n",
       "      <th>masked_sentence</th>\n",
       "      <th>hugchat_response</th>\n",
       "      <th>hugchat_label</th>\n",
       "      <th>hugchat_comm_targeted</th>\n",
       "      <th>hugchat_explanation</th>\n",
       "      <th>hugchat_keywords</th>\n",
       "      <th>hugchat_label_processed</th>\n",
       "      <th>hugchat_comm_targeted_processed</th>\n",
       "      <th>hugchat_keywords_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23107796_gab</td>\n",
       "      <td>{'label': [0, 2, 2], 'annotator_id': [203, 204...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>['u', 'really', 'think', 'i', 'would', 'not', ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>u really think i would not have been raped by ...</td>\n",
       "      <td>u really think i would not have been raped by ...</td>\n",
       "      <td>Output Part1: Hateful Speech\\n\\nOutput Part2: ...</td>\n",
       "      <td>hateful speech</td>\n",
       "      <td>indian, bangladeshi, hindus, muslims, neo nazis</td>\n",
       "      <td>the language used in the sentence suggests an...</td>\n",
       "      <td>raped, feral, hindus, muslims, neo nazis, sex...</td>\n",
       "      <td>hate_speech</td>\n",
       "      <td>[asian, islam]</td>\n",
       "      <td>[muslim, rape, neo, nazi, raped, feral, hindu]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9995600_gab</td>\n",
       "      <td>{'label': [2, 2, 0], 'annotator_id': [27, 6, 4...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>['the', 'uk', 'has', 'threatened', 'to', 'retu...</td>\n",
       "      <td>[]</td>\n",
       "      <td>the uk has threatened to return radioactive wa...</td>\n",
       "      <td>the uk has threatened to return radioactive wa...</td>\n",
       "      <td>Output Start:\\n\\nClassification: Hate Speech\\n...</td>\n",
       "      <td>hate speech</td>\n",
       "      <td>british south asian community</td>\n",
       "      <td>this statement contains derogatory language t...</td>\n",
       "      <td>paki, radioactive waste, migrant.</td>\n",
       "      <td>hate_speech</td>\n",
       "      <td>[asian]</td>\n",
       "      <td>[paki, waste, radioactive, migrants]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1227920812235051008_twitter</td>\n",
       "      <td>{'label': [2, 2, 2], 'annotator_id': [209, 203...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,...</td>\n",
       "      <td>['if', 'english', 'is', 'not', 'imposition', '...</td>\n",
       "      <td>[]</td>\n",
       "      <td>if english is not imposition then hindi is als...</td>\n",
       "      <td>if english is not imposition then hindi is als...</td>\n",
       "      <td>Classification: Hateful\\nCommunities Targeted:...</td>\n",
       "      <td>hateful</td>\n",
       "      <td>south asian community (including but not limi...</td>\n",
       "      <td>this sentence contains several derogatory ter...</td>\n",
       "      <td>shut up, chutiya, retarded, hindi imposition</td>\n",
       "      <td>hate_speech</td>\n",
       "      <td>[asian]</td>\n",
       "      <td>[shut, hindi, imposition, chutiya, retards]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1204931715778543624_twitter</td>\n",
       "      <td>{'label': [2, 2, 2], 'annotator_id': [235, 222...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], [0, 0, 0, ...</td>\n",
       "      <td>['no', 'liberal', 'congratulated', 'hindu', 'r...</td>\n",
       "      <td>[]</td>\n",
       "      <td>no liberal congratulated hindu refugees post c...</td>\n",
       "      <td>no liberal congratulated hindu refugees post c...</td>\n",
       "      <td>Classification: Normal Speech\\n\\nTargeted Comm...</td>\n",
       "      <td>normal speech</td>\n",
       "      <td>none</td>\n",
       "      <td>the statement seems factually correct as ther...</td>\n",
       "      <td>liberal, hindu, refugees, cab, congratulation</td>\n",
       "      <td>normal_speech</td>\n",
       "      <td>[none]</td>\n",
       "      <td>[liberal, refugees, congratulated, hindus, cab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1179102559241244672_twitter</td>\n",
       "      <td>{'label': [2, 2, 2], 'annotator_id': [51, 25, ...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>['he', 'said', 'bro', 'even', 'your', 'texts',...</td>\n",
       "      <td>['&lt;user&gt;']</td>\n",
       "      <td>he said bro even your texts sound redneck what...</td>\n",
       "      <td>he said bro even your texts sound redneck what...</td>\n",
       "      <td>Output Part 1: Classification: Normal Speech\\n...</td>\n",
       "      <td>normal speech</td>\n",
       "      <td>none</td>\n",
       "      <td>this sentence appears to be casual conversati...</td>\n",
       "      <td>bro, redneck (while potentially derogatory, d...</td>\n",
       "      <td>normal_speech</td>\n",
       "      <td>[none]</td>\n",
       "      <td>[redneck, bro]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18790322_gab</td>\n",
       "      <td>{'label': [2, 1, 1], 'annotator_id': [203, 202...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['i', 'live', 'and', 'work', 'with', 'many', '...</td>\n",
       "      <td>[]</td>\n",
       "      <td>i live and work with many legal mexican immigr...</td>\n",
       "      <td>i live and work with many legal mexican immigr...</td>\n",
       "      <td>Classification: Normal Speech\\nCommunities tar...</td>\n",
       "      <td>normal speech</td>\n",
       "      <td>none</td>\n",
       "      <td>this sentence contains no derogatory language...</td>\n",
       "      <td>legal, mexico, workers</td>\n",
       "      <td>normal_speech</td>\n",
       "      <td>[none]</td>\n",
       "      <td>[legal, illegals, work, mexican]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13459307_gab</td>\n",
       "      <td>{'label': [0, 2, 0], 'annotator_id': [67, 57, ...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0,...</td>\n",
       "      <td>['in', 'britain', 'the', 'prime', 'minister', ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>in britain the prime minister a childless woma...</td>\n",
       "      <td>in britain the prime minister a childless woma...</td>\n",
       "      <td>Classification: Hateful Speech\\nCommunities Ta...</td>\n",
       "      <td>hateful speech</td>\n",
       "      <td>women, lesbians, scottish community</td>\n",
       "      <td>this sentence contains several derogatory ter...</td>\n",
       "      <td>moslem, invader, fat woman</td>\n",
       "      <td>hate_speech</td>\n",
       "      <td>[homosexual, women]</td>\n",
       "      <td>[woman, fat, moslem, invader]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1113705567782969344_twitter</td>\n",
       "      <td>{'label': [1, 2, 1], 'annotator_id': [207, 221...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['&lt;user&gt;', '&lt;user&gt;', 'there', 'shd', 'be', 'a'...</td>\n",
       "      <td>['&lt;user&gt;', '&lt;user&gt;']</td>\n",
       "      <td>Paul Paul there shd be a film called no hindus...</td>\n",
       "      <td>&lt;user&gt; &lt;user&gt; there shd be a film called no hi...</td>\n",
       "      <td>Output:\\nStart: Classification: Hate Speech\\nC...</td>\n",
       "      <td>hate speech</td>\n",
       "      <td>indian (caste), islamic</td>\n",
       "      <td>this sentence uses derogatory language toward...</td>\n",
       "      <td>no, india, hindu, film, perfect, islamic.</td>\n",
       "      <td>hate_speech</td>\n",
       "      <td>[asian, islam]</td>\n",
       "      <td>[islamic, film, hindus, perfect]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>24555628_gab</td>\n",
       "      <td>{'label': [2, 1, 1], 'annotator_id': [246, 221...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['jews', 'defends', 'jews', 'regardless', 'mus...</td>\n",
       "      <td>[]</td>\n",
       "      <td>jews defends jews regardless muslims defend mu...</td>\n",
       "      <td>jews defends jews regardless muslims defend mu...</td>\n",
       "      <td>Output Start:\\nClassification: Hate Speech\\nCo...</td>\n",
       "      <td>hate speech</td>\n",
       "      <td>jewish, islamic</td>\n",
       "      <td>this sentence is biased against both jews and...</td>\n",
       "      <td>christian europeans, judaism, islam, faith di...</td>\n",
       "      <td>hate_speech</td>\n",
       "      <td>[jewish, islam]</td>\n",
       "      <td>[european, christians, christian]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16382456_gab</td>\n",
       "      <td>{'label': [0, 0, 0], 'annotator_id': [228, 220...</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "      <td>['the', 'non', 'partisan', 'congressional', 'b...</td>\n",
       "      <td>['&lt;number&gt;', '&lt;number&gt;']</td>\n",
       "      <td>the non partisan congressional budget office c...</td>\n",
       "      <td>the non partisan congressional budget office c...</td>\n",
       "      <td>Classification: Normal Speech\\nCommunities Tar...</td>\n",
       "      <td>normal speech</td>\n",
       "      <td>none</td>\n",
       "      <td>this sentence appears to be providing factual...</td>\n",
       "      <td>congressional budget office (cbo), sens linds...</td>\n",
       "      <td>normal_speech</td>\n",
       "      <td>[none]</td>\n",
       "      <td>[immigrant, lindsey, act, graham, dream, congr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            id  \\\n",
       "0                 23107796_gab   \n",
       "1                  9995600_gab   \n",
       "2  1227920812235051008_twitter   \n",
       "3  1204931715778543624_twitter   \n",
       "4  1179102559241244672_twitter   \n",
       "5                 18790322_gab   \n",
       "6                 13459307_gab   \n",
       "7  1113705567782969344_twitter   \n",
       "8                 24555628_gab   \n",
       "9                 16382456_gab   \n",
       "\n",
       "                                          annotators  \\\n",
       "0  {'label': [0, 2, 2], 'annotator_id': [203, 204...   \n",
       "1  {'label': [2, 2, 0], 'annotator_id': [27, 6, 4...   \n",
       "2  {'label': [2, 2, 2], 'annotator_id': [209, 203...   \n",
       "3  {'label': [2, 2, 2], 'annotator_id': [235, 222...   \n",
       "4  {'label': [2, 2, 2], 'annotator_id': [51, 25, ...   \n",
       "5  {'label': [2, 1, 1], 'annotator_id': [203, 202...   \n",
       "6  {'label': [0, 2, 0], 'annotator_id': [67, 57, ...   \n",
       "7  {'label': [1, 2, 1], 'annotator_id': [207, 221...   \n",
       "8  {'label': [2, 1, 1], 'annotator_id': [246, 221...   \n",
       "9  {'label': [0, 0, 0], 'annotator_id': [228, 220...   \n",
       "\n",
       "                                          rationales  \\\n",
       "0  [[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,...   \n",
       "1  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "2  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,...   \n",
       "3  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1], [0, 0, 0, ...   \n",
       "4  [[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "5                                                 []   \n",
       "6  [[0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0,...   \n",
       "7                                                 []   \n",
       "8                                                 []   \n",
       "9  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
       "\n",
       "                                         post_tokens  \\\n",
       "0  ['u', 'really', 'think', 'i', 'would', 'not', ...   \n",
       "1  ['the', 'uk', 'has', 'threatened', 'to', 'retu...   \n",
       "2  ['if', 'english', 'is', 'not', 'imposition', '...   \n",
       "3  ['no', 'liberal', 'congratulated', 'hindu', 'r...   \n",
       "4  ['he', 'said', 'bro', 'even', 'your', 'texts',...   \n",
       "5  ['i', 'live', 'and', 'work', 'with', 'many', '...   \n",
       "6  ['in', 'britain', 'the', 'prime', 'minister', ...   \n",
       "7  ['<user>', '<user>', 'there', 'shd', 'be', 'a'...   \n",
       "8  ['jews', 'defends', 'jews', 'regardless', 'mus...   \n",
       "9  ['the', 'non', 'partisan', 'congressional', 'b...   \n",
       "\n",
       "              masked_tokens  \\\n",
       "0                        []   \n",
       "1                        []   \n",
       "2                        []   \n",
       "3                        []   \n",
       "4                ['<user>']   \n",
       "5                        []   \n",
       "6                        []   \n",
       "7      ['<user>', '<user>']   \n",
       "8                        []   \n",
       "9  ['<number>', '<number>']   \n",
       "\n",
       "                                   unmasked_sentence  \\\n",
       "0  u really think i would not have been raped by ...   \n",
       "1  the uk has threatened to return radioactive wa...   \n",
       "2  if english is not imposition then hindi is als...   \n",
       "3  no liberal congratulated hindu refugees post c...   \n",
       "4  he said bro even your texts sound redneck what...   \n",
       "5  i live and work with many legal mexican immigr...   \n",
       "6  in britain the prime minister a childless woma...   \n",
       "7  Paul Paul there shd be a film called no hindus...   \n",
       "8  jews defends jews regardless muslims defend mu...   \n",
       "9  the non partisan congressional budget office c...   \n",
       "\n",
       "                                     masked_sentence  \\\n",
       "0  u really think i would not have been raped by ...   \n",
       "1  the uk has threatened to return radioactive wa...   \n",
       "2  if english is not imposition then hindi is als...   \n",
       "3  no liberal congratulated hindu refugees post c...   \n",
       "4  he said bro even your texts sound redneck what...   \n",
       "5  i live and work with many legal mexican immigr...   \n",
       "6  in britain the prime minister a childless woma...   \n",
       "7  <user> <user> there shd be a film called no hi...   \n",
       "8  jews defends jews regardless muslims defend mu...   \n",
       "9  the non partisan congressional budget office c...   \n",
       "\n",
       "                                    hugchat_response    hugchat_label  \\\n",
       "0  Output Part1: Hateful Speech\\n\\nOutput Part2: ...   hateful speech   \n",
       "1  Output Start:\\n\\nClassification: Hate Speech\\n...      hate speech   \n",
       "2  Classification: Hateful\\nCommunities Targeted:...          hateful   \n",
       "3  Classification: Normal Speech\\n\\nTargeted Comm...    normal speech   \n",
       "4  Output Part 1: Classification: Normal Speech\\n...    normal speech   \n",
       "5  Classification: Normal Speech\\nCommunities tar...    normal speech   \n",
       "6  Classification: Hateful Speech\\nCommunities Ta...   hateful speech   \n",
       "7  Output:\\nStart: Classification: Hate Speech\\nC...      hate speech   \n",
       "8  Output Start:\\nClassification: Hate Speech\\nCo...      hate speech   \n",
       "9  Classification: Normal Speech\\nCommunities Tar...    normal speech   \n",
       "\n",
       "                               hugchat_comm_targeted  \\\n",
       "0    indian, bangladeshi, hindus, muslims, neo nazis   \n",
       "1                      british south asian community   \n",
       "2   south asian community (including but not limi...   \n",
       "3                                               none   \n",
       "4                                               none   \n",
       "5                                               none   \n",
       "6                women, lesbians, scottish community   \n",
       "7                            indian (caste), islamic   \n",
       "8                                    jewish, islamic   \n",
       "9                                               none   \n",
       "\n",
       "                                 hugchat_explanation  \\\n",
       "0   the language used in the sentence suggests an...   \n",
       "1   this statement contains derogatory language t...   \n",
       "2   this sentence contains several derogatory ter...   \n",
       "3   the statement seems factually correct as ther...   \n",
       "4   this sentence appears to be casual conversati...   \n",
       "5   this sentence contains no derogatory language...   \n",
       "6   this sentence contains several derogatory ter...   \n",
       "7   this sentence uses derogatory language toward...   \n",
       "8   this sentence is biased against both jews and...   \n",
       "9   this sentence appears to be providing factual...   \n",
       "\n",
       "                                    hugchat_keywords hugchat_label_processed  \\\n",
       "0   raped, feral, hindus, muslims, neo nazis, sex...             hate_speech   \n",
       "1                  paki, radioactive waste, migrant.             hate_speech   \n",
       "2       shut up, chutiya, retarded, hindi imposition             hate_speech   \n",
       "3      liberal, hindu, refugees, cab, congratulation           normal_speech   \n",
       "4   bro, redneck (while potentially derogatory, d...           normal_speech   \n",
       "5                             legal, mexico, workers           normal_speech   \n",
       "6                         moslem, invader, fat woman             hate_speech   \n",
       "7          no, india, hindu, film, perfect, islamic.             hate_speech   \n",
       "8   christian europeans, judaism, islam, faith di...             hate_speech   \n",
       "9   congressional budget office (cbo), sens linds...           normal_speech   \n",
       "\n",
       "  hugchat_comm_targeted_processed  \\\n",
       "0                  [asian, islam]   \n",
       "1                         [asian]   \n",
       "2                         [asian]   \n",
       "3                          [none]   \n",
       "4                          [none]   \n",
       "5                          [none]   \n",
       "6             [homosexual, women]   \n",
       "7                  [asian, islam]   \n",
       "8                 [jewish, islam]   \n",
       "9                          [none]   \n",
       "\n",
       "                          hugchat_keywords_processed  \n",
       "0     [muslim, rape, neo, nazi, raped, feral, hindu]  \n",
       "1               [paki, waste, radioactive, migrants]  \n",
       "2        [shut, hindi, imposition, chutiya, retards]  \n",
       "3  [liberal, refugees, congratulated, hindus, cab...  \n",
       "4                                     [redneck, bro]  \n",
       "5                   [legal, illegals, work, mexican]  \n",
       "6                      [woman, fat, moslem, invader]  \n",
       "7                   [islamic, film, hindus, perfect]  \n",
       "8                  [european, christians, christian]  \n",
       "9  [immigrant, lindsey, act, graham, dream, congr...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d030aad6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
